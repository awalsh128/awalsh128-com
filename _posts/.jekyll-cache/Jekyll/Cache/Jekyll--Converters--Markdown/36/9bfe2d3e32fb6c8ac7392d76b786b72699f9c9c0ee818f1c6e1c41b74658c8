I"œ<h3 id="introduction">Introduction</h3>

<p>If you are already familiar with <a href="http://en.wikipedia.org/wiki/Finite-state_machine">finite
automata</a>, then
understanding a <a href="http://en.wikipedia.org/wiki/Markov_chain">Markov
chain</a> will not be as hard.
If you are not familiar with one, you can think of finite automata as a
<a href="http://en.wikipedia.org/wiki/Flowchart">flowchart</a>, with states and
paths leading from one state to another <a href="http://xkcd.com/627/">based on some decision being
made</a>. An example could be a room with a light
switch; there are the two states of having the light on or off. Using
the light switch will transition you between the two states.</p>

<p>::: {.separator style=‚Äùclear: both; text-align: center;‚Äù}
<a href="http://2.bp.blogspot.com/-_8ivI0g-2pY/UJsLfG04cRI/AAAAAAAADRU/HOFVAJKwYqc/s1600/simple-automata.png"><img src="http://2.bp.blogspot.com/-_8ivI0g-2pY/UJsLfG04cRI/AAAAAAAADRU/HOFVAJKwYqc/s400/simple-automata.png" alt="" />{width=‚Äù400‚Äù
height=‚Äù183‚Äù}</a>
:::</p>

<p>The difference between standard finite automata and Markov chains is
that instead of having some definite outcome determining each path (eg.
yes or no), they are probabilities. Take for example a coin flip, there
is a 50% (0.5) chance that it could either be heads or tails.</p>

<p>::: {.separator style=‚Äùclear: both; text-align: center;‚Äù}
<a href="http://4.bp.blogspot.com/-At-x9TP5t44/UJsLwCzq81I/AAAAAAAADRg/IFNPH1QKU8U/s1600/simple-markov.png"><img src="http://4.bp.blogspot.com/-At-x9TP5t44/UJsLwCzq81I/AAAAAAAADRg/IFNPH1QKU8U/s400/simple-markov.png" alt="" />{width=‚Äù400‚Äù
height=‚Äù259‚Äù}</a>
:::</p>

<h3 id="an-example">An Example</h3>

<p>Let's explore Markov chains a little deeper with respect to natural
languages and take a look at some sample text that will form the
<a href="http://en.wikipedia.org/wiki/Text_corpus">corpus</a> of our analysis.</p>

<p>‚ÄúI like turtles. I like rabbits. I don't like snails.‚Äù</p>

<p>This would render a Markov chain as follows:</p>

<p>::: {.separator style=‚Äùclear: both; text-align: center;‚Äù}
<a href="http://2.bp.blogspot.com/-U2fyhOJ7bN8/UJsL23oh3zI/AAAAAAAADRs/wZNWvVR-Jco/s1600/text-markov.png"><img src="http://2.bp.blogspot.com/-U2fyhOJ7bN8/UJsL23oh3zI/AAAAAAAADRs/wZNWvVR-Jco/s400/text-markov.png" alt="" />{width=‚Äù400‚Äù
height=‚Äù345‚Äù}</a>
:::</p>

<p>The above chain means that, among the sentences:</p>

<ul>
  <li>100% (1.0) will start with <em>I</em>.</li>
  <li>This will be followed by <em>like</em> for 66% (0.66) of the time and
<em>don't</em> for 33% (0.33) of the time.</li>
  <li>The word <em>don't</em> will always (100% / 1.0) be followed by <em>like</em>.</li>
  <li>Then lastly, <em>turtles</em>, <em>rabbits</em> and <em>snails</em> will all follow
<em>like</em> 33% (0.33) of the time.</li>
</ul>

<p>The nice thing about Markov chains, with respect to natural language
modelling, is that they form <a href="http://en.wikipedia.org/wiki/Dependency_grammar">word
dependencies</a> without
any knowledge of the language's syntax or semantics. The chain gets
created purely based on statistical knowledge extracted from the corpus.</p>

<h3 id="text-generation">Text Generation</h3>

<h2 id="random-selection">Random Selection</h2>

<p>Using the Markov chain example from before and taking the weight of
probabilities into account, we can randomly traverse the chain to
generate new sentences like:</p>

<p>‚ÄúI don't like turtles. I like snails.‚Äù</p>

<p>Although, our small corpus does not make for very interesting or new
text. We could make it more interesting by adding to it or switching to
a much larger corpus altogether. In my case, I decided to take all of
<a href="https://raw.github.com/awalsh128/nlp/master/sonnets.txt">Shakespear's
sonnets</a> and
generate the text from that. You can see some example code that uses it
as the corpus below.</p>

<h2 id="the-code">The Code</h2>

<p>The Markov chains will be built up for each new sentence it comes
across. The critical parts to the <code class="language-plaintext highlighter-rouge">MarkovChain</code> object are its:</p>

<ul>
  <li><strong>Cardinalities</strong>: The cardinality of the sample space for a given
state. In our original example, the cardinality of <em>like</em> is 3 since
snails, rabbits and turtles follow out of the <em>like</em> state. The
cardinality of <em>I</em> would be 2 since <em>don't</em> and <em>like</em> follow.</li>
  <li><strong>Occurrences</strong>: The edge valued occurrences between the different
states. For example, a transition from the <em>I</em> to <em>like</em> state
occurred twice. The probability can then be easily calculated by
taking the number of occurrences on a transition and divide it by
the cardinality of the state's sample space. Note, there is also a
special start state transition that can be used at the beginning of
each new sentence generation.</li>
</ul>

<p>Using these two parts, a random walk can be made across a chain path,
starting from the special start state. Each walk will generate a new
sentence based on probabilities of the transitions along the path.</p>

<p>\</p>

<p>\</p>

<h3 id="additional-resources">Additional Resources</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Stochastic_grammar">Wikipedia: Stochastic
Grammar</a></li>
  <li><a href="http://en.wikipedia.org/wiki/Natural_language_generation">Wikipedia: Natural language
generation</a></li>
  <li><a href="http://www.cs.princeton.edu/courses/archive/spr05/cos126/assignments/markov.html">Princeton CS206: Markov Model of Natural
Language</a></li>
  <li><a href="http://www.owlnet.rice.edu/~cz1/prog/markov/markov.html">Markov-chain Text
Generator</a></li>
  <li><a href="http://www.siggen.org/">ACL Special Interest Group on Natural Language Generation
(SIGGEN)</a></li>
</ul>
:ET